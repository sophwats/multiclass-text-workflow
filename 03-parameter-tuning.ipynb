{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models we have trained have parameters which must be tuned. It's common practice to train models using a few different parameter values, and see how they impact the model. \n",
    "\n",
    "It can also be necessary to retune your model's parameters after your model has been running in production for a while - perhaps the data has drifted, and as such the model should be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we load in the feature engineering and model training pipeline stages developed in the previous notebooks, and do a parameter sweep to identify the best model parameters from a candidate set. \n",
    "\n",
    "We start by loaing in the training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os.path\n",
    "\n",
    "training_data = pd.read_parquet(os.path.join(\"data\", \"training.parquet\"))\n",
    "testing_data = pd.read_parquet(os.path.join(\"data\", \"testing.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load in the feature engineering and model pipeline stages which were developed in the previous notebooks. We will then combine them into one pipeline, which takes in raw data and returns a prediction.\n",
    "\n",
    "Note: If you didn't run atleast one feature engineering notebook and one model training notebook fully, this next cell will return an error when it is run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading in feature extraction pipeline\n",
    "import cloudpickle as cp\n",
    "feature_pipeline = cp.load(open('feature_pipeline.sav', 'rb'))\n",
    "\n",
    "model = cp.load(open('model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('features',feature_pipeline),\n",
    "    ('model',model)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline can be fit to data (in the same way that we fit the individual feature engineering and model training techniquest to the data in the previous notebooks). We can also evaluate the model using the test set, as we did previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 Pipeline(steps=[('vect',\n",
       "                                  HashingVectorizer(alternate_sign=False,\n",
       "                                                    n_features=2048, norm=None,\n",
       "                                                    stop_words='english',\n",
       "                                                    token_pattern='(?u)\\\\b[A-Za-z]\\\\w+\\\\b')),\n",
       "                                 ('tfidf', TfidfTransformer())])),\n",
       "                ('model', MultinomialNB())])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(training_data[\"Text\"], training_data[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlworkflows import plot\n",
    "df, chart = plot.confusion_matrix(testing_data.Category, nb.predict(testing_vecs))\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
